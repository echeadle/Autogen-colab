{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPGT6F3NZoeAKxr6nG8+Vh1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/echeadle/Autogen-colab/blob/main/UdemyAutogen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y16SnFa0yDwL",
        "outputId": "ba493c7c-f250-4817-f51d-8d0ee1a857a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyautogen in /usr/local/lib/python3.10/dist-packages (0.2.27)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: diskcache in /usr/local/lib/python3.10/dist-packages (from pyautogen) (5.6.3)\n",
            "Requirement already satisfied: docker in /usr/local/lib/python3.10/dist-packages (from pyautogen) (7.0.0)\n",
            "Requirement already satisfied: flaml in /usr/local/lib/python3.10/dist-packages (from pyautogen) (2.1.2)\n",
            "Requirement already satisfied: numpy<2,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from pyautogen) (1.25.2)\n",
            "Requirement already satisfied: openai>=1.3 in /usr/local/lib/python3.10/dist-packages (from pyautogen) (1.28.1)\n",
            "Requirement already satisfied: pydantic!=2.6.0,<3,>=1.10 in /usr/local/lib/python3.10/dist-packages (from pyautogen) (2.7.1)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (from pyautogen) (1.0.1)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from pyautogen) (2.4.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from pyautogen) (0.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->pyautogen) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.3->pyautogen) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->pyautogen) (0.27.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->pyautogen) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->pyautogen) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->pyautogen) (4.11.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=2.6.0,<3,>=1.10->pyautogen) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=2.6.0,<3,>=1.10->pyautogen) (2.18.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from docker->pyautogen) (2.31.0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from docker->pyautogen) (2.0.7)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->pyautogen) (2023.12.25)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.3->pyautogen) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.3->pyautogen) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai>=1.3->pyautogen) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai>=1.3->pyautogen) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.3->pyautogen) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->docker->pyautogen) (3.3.2)\n"
          ]
        }
      ],
      "source": [
        "pip install pyautogen matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from autogen import ConversableAgent\n"
      ],
      "metadata": {
        "id": "WsqxtLfzyPAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_config = {\n",
        "    \"model\": \"gpt-3.5-turbo\",\n",
        "    \"api_key\": userdata.get(\"OPENAI_API_KEY\"),\n",
        "    \"temperature\": 0.8\n",
        "}"
      ],
      "metadata": {
        "id": "lB1Jh1LXympe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audiance = ConversableAgent(\n",
        "    name=\"audiance\",\n",
        "    llm_config = llm_config,\n",
        "    is_termination_msg= lambda msg: 'HAHA' in msg['content'].upper(),\n",
        "    system_message='You are a member of the audiance of a comedy show that is hard to impress.'\n",
        ")"
      ],
      "metadata": {
        "id": "RD8VWmLczNl1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comedian = ConversableAgent(\n",
        "    name=\"comedian\",\n",
        "    llm_config = llm_config,\n",
        "    max_consecutive_auto_reply=2,\n",
        "    system_message='You are a comedian that tells bad jokes'\n",
        ")"
      ],
      "metadata": {
        "id": "YK8AptPr7AVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comedian.initiate_chat(\n",
        "    audiance,\n",
        "    message=\"Welcome to my standup comedy show! Are you ready for a night full of laughter?\",\n",
        "    max_turns = 2\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qll4XHZk6MTF",
        "outputId": "526128c7-a1d6-4757-981d-7b008235cf61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "comedian (to audiance):\n",
            "\n",
            "Welcome to my standup comedy show! Are you ready for a night full of laughter?\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> USING AUTO REPLY...\n",
            "audiance (to comedian):\n",
            "\n",
            "We'll see about that. Impress us!\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> USING AUTO REPLY...\n",
            "comedian (to audiance):\n",
            "\n",
            "Alright, here we go! Why did the scarecrow win an award? Because he was outstanding in his field!\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> USING AUTO REPLY...\n",
            "audiance (to comedian):\n",
            "\n",
            "(chuckles) Not bad, not bad. Keep 'em coming!\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatResult(chat_id=None, chat_history=[{'content': 'Welcome to my standup comedy show! Are you ready for a night full of laughter?', 'role': 'assistant'}, {'content': \"We'll see about that. Impress us!\", 'role': 'user'}, {'content': 'Alright, here we go! Why did the scarecrow win an award? Because he was outstanding in his field!', 'role': 'assistant'}, {'content': \"(chuckles) Not bad, not bad. Keep 'em coming!\", 'role': 'user'}], summary=\"(chuckles) Not bad, not bad. Keep 'em coming!\", cost={'usage_including_cached_inference': {'total_cost': 0.000161, 'gpt-3.5-turbo-0125': {'cost': 0.000161, 'prompt_tokens': 184, 'completion_tokens': 46, 'total_tokens': 230}}, 'usage_excluding_cached_inference': {'total_cost': 0.000161, 'gpt-3.5-turbo-0125': {'cost': 0.000161, 'prompt_tokens': 184, 'completion_tokens': 46, 'total_tokens': 230}}}, human_input=[])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from autogen import ConversableAgent"
      ],
      "metadata": {
        "id": "EwCU7PQMDq2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_config = {\n",
        "    \"model\": \"gpt-3.5-turbo\",\n",
        "    \"api_key\": userdata.get(\"OPENAI_API_KEY\"),\n",
        "    \"temperature\": 0.8\n",
        "}"
      ],
      "metadata": {
        "id": "4z_3P-gEEkDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_guesser = ConversableAgent(\n",
        "    name=\"agent_guesser\",\n",
        "    system_message=\"\"\"Let's play a game. I have a person in mind, and you have to guess it.\n",
        "    I'll respond with 'yes' or 'no' with a hint. Don't ask questions just make best use of\n",
        "    information you already have received and return person's name. Go ahead and start guessing!\"\"\",\n",
        "    max_consecutive_auto_reply=1,\n",
        "    llm_config=llm_config,\n",
        "    human_input_mode=\"TERMENATE\",\n",
        ")\n",
        "\n",
        "agent_thinker = ConversableAgent(\n",
        "    name=\"agent_thinker\",\n",
        "    system_message=\"\"\"Let's play a game.  Think of a famous personality, and I'll try to guess\n",
        "    their name on every turn. Respond with 'yes' or 'no'. If no, also provide a hint. Let's get started\"\"\",\n",
        "    llm_config=llm_config,\n",
        "    human_input_mode=\"NEVER\",\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "siQhM9tdkyhe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = agent_thinker.initiate_chat(\n",
        "    agent_guesser,\n",
        "    message=\"Let's start. I have someone in mind.\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2V_CB2fo270",
        "outputId": "d3b32fac-2e33-4f66-aa5e-9ea47442a55c"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "agent_thinker (to agent_guesser):\n",
            "\n",
            "Let's start. I have someone in mind.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> USING AUTO REPLY...\n",
            "agent_guesser (to agent_thinker):\n",
            "\n",
            "Is the person you have in mind a fictional character?\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "agent_thinker (to agent_guesser):\n",
            "\n",
            "No\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Please give feedback to agent_thinker. Press enter to skip and use auto-reply, or type 'exit' to stop the conversation: \n",
            "\n",
            ">>>>>>>> NO HUMAN INPUT RECEIVED.\n",
            "\n",
            ">>>>>>>> USING AUTO REPLY...\n",
            "agent_guesser (to agent_thinker):\n",
            "\n",
            "Is the person you have in mind a historical figure?\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "agent_thinker (to agent_guesser):\n",
            "\n",
            "Yes\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Please give feedback to agent_thinker. Press enter to skip and use auto-reply, or type 'exit' to stop the conversation: \n",
            "\n",
            ">>>>>>>> NO HUMAN INPUT RECEIVED.\n",
            "\n",
            ">>>>>>>> USING AUTO REPLY...\n",
            "agent_guesser (to agent_thinker):\n",
            "\n",
            "Is the person you have in mind a political figure?\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "agent_thinker (to agent_guesser):\n",
            "\n",
            "Yes\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Please give feedback to agent_thinker. Press enter to skip and use auto-reply, or type 'exit' to stop the conversation: Is the person an american\n",
            "agent_guesser (to agent_thinker):\n",
            "\n",
            "Is the person an american\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "agent_thinker (to agent_guesser):\n",
            "\n",
            "Yes\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> USING AUTO REPLY...\n",
            "agent_guesser (to agent_thinker):\n",
            "\n",
            "Is the person you have in mind a former president of the United States?\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "agent_thinker (to agent_guesser):\n",
            "\n",
            "Yes\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Please give feedback to agent_thinker. Press enter to skip and use auto-reply, or type 'exit' to stop the conversation: \n",
            "\n",
            ">>>>>>>> NO HUMAN INPUT RECEIVED.\n",
            "\n",
            ">>>>>>>> USING AUTO REPLY...\n",
            "agent_guesser (to agent_thinker):\n",
            "\n",
            "Is the person you have in mind Barack Obama?\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "agent_thinker (to agent_guesser):\n",
            "\n",
            "Yes, you got it! It's Barack Obama. Great job!\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Please give feedback to agent_thinker. Press enter to skip and use auto-reply, or type 'exit' to stop the conversation: exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "from autogen import ConversableAgent\n",
        "from autogen.coding import LocalCommandLineCodeExecutor\n",
        "\n",
        "executor = LocalCommandLineCodeExecutor(\n",
        "    timeout=10,\n",
        "    work_dir='code/',\n",
        ")\n",
        "\n",
        "code_executor_agent = ConversableAgent(\n",
        "    name=\"code_executor_agent\",\n",
        "    llm_config=False,\n",
        "    code_execution_config={\"executor\": executor},\n",
        "    human_input_mode=\"NEVER\",\n",
        ")\n",
        "message_with_code_block = \"\"\"\n",
        "Here's a code that solves your problem:\n",
        "```python\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a DataFrame with sample data\n",
        "data = pd.DataFrame({\n",
        "  'x': np.arange(10),\n",
        "  'y': np.random.randint(0, 10, 10)\n",
        "})\n",
        "\n",
        "# Plot the line plot\n",
        "plt.plot(data['x'], data['y'])\n",
        "plt.xlabel('X-axis')\n",
        "plt.ylabel('Y-axis')\n",
        "plt.title('Line Plot')\n",
        "plt.savefig('lineplot.png')\n",
        "plt.show()\n",
        "print('Line plot saved to lineplot.png')\n",
        "```\n",
        "\"\"\"\n",
        "reply = code_executor_agent.generate_reply(messages=[{\"role\": \"user\",\n",
        "                                                     \"content\": message_with_code_block}])\n",
        "print(reply)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckfaxts0umfw",
        "outputId": "7e5a7df1-bc8c-45ad-9020-d2fb271d0906"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            ">>>>>>>> EXECUTING CODE BLOCK (inferred language is python)...\n",
            "exitcode: 0 (execution succeeded)\n",
            "Code output: Figure(640x480)\n",
            "Line plot saved to lineplot.png\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "code_assistant_system_message = \"\"\"You are a helpful AI assistant.\n",
        "Solve tasks user you coding and language skills.\n",
        "In the following cases, suggest python code (in a python coding block) or shell script (in a sh coding block)\n",
        "1. When you need to collect info, use the code to output the info you need, for example, browse or search the web,\n",
        "2. When you need to perform some task with code, user the code to perform the task and output the result. Finish the\n",
        "Solve the task step by step if you need to. If a plan is not provided, explain your plan first. Be clear which step\n",
        "when using code, you must indicate the script type in the code block. The user connot provide any other feedback or\n",
        "If you want the  user to save the code in a file before executing it, put # filename: <filename> inside the code block\n",
        "If the result indicates there is an error, fix the error and output the code again. Suggest the full code instead\n",
        "When you find an answer, verify the answer carefully. Include verifiable evidence in your response if possible.\n",
        "Reply 'TERMINATE' in the end when everything is done.\n",
        "\"\"\"\n",
        "\n",
        "llm_config= {\n",
        "    \"model\": \"gpt-3.5-turbo\",\n",
        "    \"api_key\": userdata.get(\"OPENAI_API_KEY\"),\n",
        "    \"temperature\": 0.7\n",
        "}\n",
        "\n",
        "code_assistant = ConversableAgent(\n",
        "    \"code_assistant\",\n",
        "    llm_config=llm_config,\n",
        "    system_message=code_assistant_system_message,\n",
        "    code_execution_config=False\n",
        ")"
      ],
      "metadata": {
        "id": "rN_yr-H9uK3W"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_result = code_executor_agent.initiate_chat(\n",
        "    code_assistant,\n",
        "    message=\"Write Python code to calculate the 23rd prime number\",\n",
        "    max_turns=2\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLh_CsgR-5yv",
        "outputId": "d0bcae35-2cd8-4713-e7a5-05d6b89b0e99"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "code_executor_agent (to code_assistant):\n",
            "\n",
            "Write Python code to calculate the 23rd prime number\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> USING AUTO REPLY...\n",
            "code_assistant (to code_executor_agent):\n",
            "\n",
            "To calculate the 23rd prime number, we can write a function to check if a number is prime and then iterate through numbers to find the 23rd prime number.\n",
            "\n",
            "Here is the Python code:\n",
            "\n",
            "```python\n",
            "def is_prime(num):\n",
            "    if num < 2:\n",
            "        return False\n",
            "    for i in range(2, int(num**0.5) + 1):\n",
            "        if num % i == 0:\n",
            "            return False\n",
            "    return True\n",
            "\n",
            "count = 0\n",
            "num = 2\n",
            "\n",
            "while True:\n",
            "    if is_prime(num):\n",
            "        count += 1\n",
            "        if count == 23:\n",
            "            print(num)\n",
            "            break\n",
            "    num += 1\n",
            "```\n",
            "\n",
            "This code defines a function `is_prime` to check if a number is prime, and then it iterates through numbers starting from 2 to find the 23rd prime number.\n",
            "\n",
            "You can run this code to calculate the 23rd prime number. Let me know if you need any further assistance.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> EXECUTING CODE BLOCK (inferred language is python)...\n",
            "code_executor_agent (to code_assistant):\n",
            "\n",
            "exitcode: 0 (execution succeeded)\n",
            "Code output: 83\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> USING AUTO REPLY...\n",
            "code_assistant (to code_executor_agent):\n",
            "\n",
            "The 23rd prime number is 83. The Python code provided earlier has successfully calculated the 23rd prime number. \n",
            "\n",
            "If you have any more tasks or questions, feel free to ask!\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}